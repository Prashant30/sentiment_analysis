{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_with_a_simple_NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVpK-yuYZHNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import necessary libraries\n",
        "import numpy as np\n",
        "import json\n",
        "import csv\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.preprocessing import text, sequence\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Activation, Dropout, Dense\n",
        "from tensorflow.python.keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HguHVGmsHZ0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reading file to train the neural network\n",
        "\n",
        "with open(\"/content/sample_data/nlp_train.json\") as data_file:\n",
        "  data = json.load(data_file)\n",
        "  y_pandas_df = []\n",
        "  x_pandas_df = []\n",
        "  i=0\n",
        "  for v in data.values():\n",
        "    y_pandas_df.insert(-1,v[\"emotion\"])\n",
        "    i=i+1\n",
        "    x_pandas_df.insert(-1,v[\"body\"])\n",
        "ydf = [ [0] * 12 for _ in range(1493)]\n",
        "# print(y)\n",
        "i=0\n",
        "# print(y_pandas_df[2])\n",
        "for a in y_pandas_df:\n",
        "  if(a[\"anger\"]):\n",
        "    ydf[i][0]=1\n",
        "  if(a[\"anticipation\"]):\n",
        "    ydf[i][1]=1\n",
        "  if(a[\"disgust\"]):\n",
        "    ydf[i][2]=1\n",
        "  if(a[\"fear\"]):\n",
        "    ydf[i][3]=1\n",
        "  if(a[\"joy\"]):\n",
        "    ydf[i][4]=1\n",
        "  if(a[\"love\"]):\n",
        "    ydf[i][5]=1\n",
        "  if(a[\"optimism\"]):\n",
        "    ydf[i][6]=1\n",
        "  if(a[\"pessimism\"]):\n",
        "    ydf[i][7]=1\n",
        "  if(a[\"sadness\"]):\n",
        "    ydf[i][8]=1\n",
        "  if(a[\"surprise\"]):\n",
        "    ydf[i][9]=1\n",
        "  if(a[\"trust\"]):\n",
        "    ydf[i][10]=1\n",
        "  if(a[\"neutral\"]):\n",
        "    ydf[i][11]=1\n",
        "  i=i+1\n",
        "# print(y)\n",
        "x=np.asarray(x_pandas_df)\n",
        "y = np.asarray(ydf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQGCqXEoObGQ",
        "colab_type": "code",
        "outputId": "4c032d2c-58db-41c3-e16f-e3bac7769ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# checking the properties of y, whether it is in correct format to give input to NN\n",
        "print(\"properties of y\")\n",
        "print(\"type : {}, dimensions : {}, shape : {}, total no. of elements : {}, data type of each element: {}, size of each element {} bytes\".format(type(y), y.ndim, y.shape, y.size, y.dtype, y.itemsize))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "properties of y\n",
            "type : <class 'numpy.ndarray'>, dimensions : 2, shape : (1493, 12), total no. of elements : 17916, data type of each element: int64, size of each element 8 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXxx4-l4LJgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining Parameters of the model. These are randomly chosen, feel free to change parameters to get better learning accuracy.\n",
        "list_of_classes = ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust', 'neutral']\n",
        "max_features = 20000\n",
        "max_text_length = 400\n",
        "embedding_dims = 50\n",
        "batch_size = 32\n",
        "epochs = 5\n",
        "num_filters_1 = 250\n",
        "num_filters_2 = 250\n",
        "filter_size = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-SCn6wYLFCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tokenizer = text.Tokenizer(num_words=max_features)\n",
        "x_tokenizer.fit_on_texts(list(x))\n",
        "x_tokenized = x_tokenizer.texts_to_sequences(x)\n",
        "x_train_val = sequence.pad_sequences(x_tokenized, maxlen=max_text_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu0aYqiDMlTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining the model\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(max_features, embedding_dims, input_length=max_text_length))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv1D(filters=num_filters_1, kernel_size=filter_size, padding='valid', activation='relu', strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "model.add(Dense(num_filters_2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(12))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAJcgdTSMoHD",
        "colab_type": "code",
        "outputId": "6940affa-5531-4039-c439-23654ba6d623",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 400, 50)           1000000   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 400, 50)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 398, 250)          37750     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 250)               62750     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 12)                3012      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 12)                0         \n",
            "=================================================================\n",
            "Total params: 1,103,512\n",
            "Trainable params: 1,103,512\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2ez0bbKMr8M",
        "colab_type": "code",
        "outputId": "c3a2c356-4a74-4e59-bae2-a8c6fe258bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# training the model with train data\n",
        "model.fit(x_train_val, y, batch_size=batch_size, epochs=epochs)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "47/47 [==============================] - 5s 103ms/step - loss: 0.5736 - accuracy: 0.2050\n",
            "Epoch 2/5\n",
            "47/47 [==============================] - 5s 103ms/step - loss: 0.5359 - accuracy: 0.2284\n",
            "Epoch 3/5\n",
            "47/47 [==============================] - 5s 104ms/step - loss: 0.5283 - accuracy: 0.2458\n",
            "Epoch 4/5\n",
            "47/47 [==============================] - 5s 103ms/step - loss: 0.5206 - accuracy: 0.2378\n",
            "Epoch 5/5\n",
            "47/47 [==============================] - 5s 103ms/step - loss: 0.5036 - accuracy: 0.2793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f175f787a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QYx9bNhVizw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving the model so that I don't have to run the training code again for testing purpose\n",
        "# because training takes lot of time.\n",
        "model.save('/content/sample_data/emo_class_keras_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwbkGOC1sfPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# our favorite part. testing the model with data\n",
        "# output will be saved in solution.csv\n",
        "\n",
        "def predict2(test_set):\n",
        "  global x_tokenizer\n",
        "  model2 = load_model('/content/sample_data/emo_class_keras_model.h5')\n",
        "  x_test2 = []\n",
        "  with open(test_set) as data_file:\n",
        "    data = json.load(data_file)\n",
        "    i=0\n",
        "    for v in data.values():\n",
        "      x_test2.insert(-1,v[\"body\"])\n",
        "      i=i+1\n",
        "  print(i)\n",
        "  x_test_tokenized2 = x_tokenizer.texts_to_sequences(x_test2)\n",
        "  print(type(x_test_tokenized2))\n",
        "  x_testing2 = sequence.pad_sequences(x_test_tokenized2, maxlen=max_text_length)\n",
        "  y_testing2 = model2.predict(x_testing2, verbose = 1)\n",
        "  sample_submission = pd.read_csv(\"/content/sample_data/submission.csv\")\n",
        "  sample_submission[list_of_classes] = y_testing2\n",
        "  sample_submission.to_csv(\"/content/sample_data/solution.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vksknwU-skPE",
        "colab_type": "code",
        "outputId": "de4accc8-8642-4d4c-c9a2-630389899f80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "predict2(\"/content/sample_data/nlp_test.json\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "374\n",
            "<class 'list'>\n",
            "12/12 [==============================] - 0s 22ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-dfc7517e523a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/sample_data/nlp_test.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-54cc0a38c521>\u001b[0m in \u001b[0;36mpredict2\u001b[0;34m(test_set)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mx_testing2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_tokenized2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_text_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0my_testing2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_testing2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0msample_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/sample_data/submission.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist_of_classes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_testing2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0msample_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/sample_data/solution.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /content/sample_data/submission.csv does not exist: '/content/sample_data/submission.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxNj8OThX55l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}